{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepKLM : 신경망 언어모델을 활용한 언어 실험을 위한 라이브러리 (가칭)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 초기 설정\n",
    "\n",
    "아래 셀을 실행하여 초기 설정을 수행해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!bash ./scripts/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "from scripts.surprisal import bert_token_surprisal, bert_sentence_surprisal, confusion_score, confusion_score_batch\n",
    "from scripts.visualization import attention_heatmap, visualize_attention_head\n",
    "from scripts.boxplot_creator import draw_box_plot\n",
    "from scripts.barplot_creator import draw_bar_plot\n",
    "\n",
    "from sys import platform\n",
    "from os import path\n",
    "from torch import device\n",
    "from transformers import AdamW, BertConfig, BertModel, BertTokenizer, BertForMaskedLM\n",
    "from bertviz_lin.pytorch_pretrained_bert import BertForTokenClassification\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\": \n",
    "    flist = fm.get_fontconfig_fonts()\n",
    "    available_fonts = [fm.FontProperties(fname=fname).get_name() for fname in flist]\n",
    "    if 'NanumGothic' in available_fonts:\n",
    "        plt.rcParams['font.family'] = 'NanumGothic'\n",
    "    else:\n",
    "        print(\"Font NanumGothic was not found... Try installing a font\")\n",
    "        !apt-get update -qq\n",
    "        !apt-get install fonts-nanum* -qq\n",
    "        print(\"Installed the font!\")\n",
    "        fm._rebuild()\n",
    "        print(\"=================IMPORTANT==============================\")\n",
    "        print(\"If on Colab, RESTART THE RUNTIME to apply the font.\")\n",
    "elif platform == \"darwin\":\n",
    "    plt.rcParams['font.family'] = 'AppleGothic' \n",
    "elif platform == \"win32\":\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "else:\n",
    "    print(\"User platform could not be identified. Korean characters may not be shown correctly when visualizing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어\n",
    "\n",
    "기본으로 버트(large, uncased)를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_model_eng = BertForMaskedLM.from_pretrained('bert-large-uncased', output_attentions=True)\n",
    "classification_model_eng = BertForTokenClassification.from_pretrained('bert-large-uncased', num_labels=2)\n",
    "tokenizer_eng = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어\n",
    "기본으로 KR-BERT를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelpath= \"./KR-BERT/krbert_pytorch/pretrained/pytorch_model_char16424_ranked.bin\"\n",
    "config = BertConfig.from_json_file(\"./KR-BERT/krbert_pytorch/pretrained/bert_config_char16424.json\")\n",
    "config.output_attentions = True\n",
    "tokenizer_kr = BertTokenizer.from_pretrained('./KR-BERT/krbert_pytorch/pretrained/vocab_snu_char16424.txt', do_lower_case=False)\n",
    "mask_model_kr =BertForMaskedLM.from_pretrained(modelpath,config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETRI의 KorBERT가 있을 경우, 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if path.exists(\"KorBERT\"):\n",
    "  sys.path.insert(1, \"./KorBERT/001_bert_morp_pytorch/src_tokenizer\")\n",
    "  import tokenization_morp\n",
    "  \"\"\"IN CASE OF ImportError:\n",
    "  1. Go to the src_tokenizer.py in KorBERT\n",
    "  2. Go to line 32 (from .file_utils import cached_path)\n",
    "  3. Change the line to the following\n",
    "    from pytorch_pretrained_bert.file_utils import cached_path\n",
    "  4. Enjoy :)\n",
    "  \"\"\"\n",
    "\n",
    "  korbert_path = \"./KorBERT/001_bert_morp_pytorch/\"\n",
    "  modelpath= korbert_path + \"pytorch_model.bin\"\n",
    "  config = BertConfig.from_json_file(korbert_path + \"bert_config.json\")\n",
    "  mask_model_etri=BertForMaskedLM.from_pretrained(modelpath,config=config)\n",
    "  tokenizer_etri = tokenization_morp.BertTokenizer.from_pretrained(korbert_path + \"vocab.korean_morp.list\")\n",
    "else:\n",
    "  print(\"KorBERT not found. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1차원) 요인설계실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사용법\n",
    "    * 공통되는 토큰을 [MASK]로 치환합니다.\n",
    "    * 입력으로 들어가는 토큰을 키워드로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "철수가 영희[MASK] 좋아한다.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bert_token_surprisal(text, [\"을\", \"를\"], mask_model_kr, tokenizer_kr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2차원) 요인설계실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사용법\n",
    "    * 공통되는 토큰을 [MASK]로 치환합니다.\n",
    "    * 입력으로 들어가는 토큰을 키워드로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "철수가 영희[MASK] 좋아한다.\n",
    "철수는 영희[MASK] 좋아한다.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bert_token_surprisal(text, [\"을\", \"를\"], mask_model_kr, tokenizer_kr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3차원) 요인설계실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 사용법\n",
    "    * 공통되는 토큰을 [MASK]로 치환합니다.\n",
    "    * 입력으로 들어가는 토큰을 키워드로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "철수가 영희[MASK] 좋아한다.\n",
    "철수가 영희[MASK] 싫어한다.\n",
    "철수는 영희[MASK] 좋아한다.\n",
    "철수가 영희[MASK] 싫어한다.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprisal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bert_token_surprisal(text, [\"을\", \"를\"], mask_model_kr, tokenizer_kr, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주의할 점\n",
    "\n",
    "- 컴퓨터의 입장에서 최소대립쌍이 맞는지 확인하여야 합니다.\n",
    "    - 가령, 철수는 자신을/자기를 사랑한다.에서, \n",
    "    - 자신, 자기만 바뀐 것이 아니라\n",
    "    - 을/를 토큰 또한 바뀌었기 떄문에\n",
    "    - 최소대립쌍이 아닙니다.\n",
    "- 버트에 \"등록된\" 단어인지 확인하여야 합니다.\n",
    "    - 효율성을 위해 버트는 '바이트 페어 인코딩'이라는 것을 수행합니다.\n",
    "    - 따라서, 단어가 (형태소와는 상관 없는) 단어보다 작은 단위로 나누어서 등록되어 있을 수 있습니다.\n",
    "    - 키워드가 \\[UNK\\]로 인식되지 않았는지 확인하셔야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Score\n",
    "from Lin et al. (2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_score(\"The scholar that published the paper has ever resigned the position\t0\t7\t4\", classification_model_eng, tokenizer_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화\n",
    "* 히트맵 시각화는 attention_heatmap()\n",
    "    * 입력값은 리스트([ ]) 안에 들어가야 합니다.\n",
    "    * vis_opt값은 0, 1, 2 중 하나로, 히트맵의 형태를 결정합니다.\n",
    "* BertViz는 visualize_attention_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attention_heatmap([\"학생들이 통사론 과제를 하지 않았다\"],\n",
    "                  mask_model_kr, tokenizer_kr, device, vis_opt=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_attention_head(mask_model_kr, tokenizer_kr, \"학생들은 통사론 과제를 제출했다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 플롯 그리기\n",
    "### 박스플롯\n",
    "* 제공된 template.xlsx 파일을 결과로 채워 주세요.\n",
    "    * 2by2 실험의 경우 factor1까지 채우시면 됩니다.\n",
    "        * factor2는 비워 두세요\n",
    "    * 2by2by2 실험의 경우 factor2까지 채우셔야 합니다.\n",
    "* boxplot_config.txt 파일을 수정해 주세요\n",
    "    * filepath = _파일 이름_\n",
    "    * factor1 = _첫 번째 요인 이름_\n",
    "    * factor1_vals = _첫 번째 요인의 변수_\n",
    "    * factor2 = _두 번째 요인 이름_\n",
    "        * 2by2 실험의 경우 비워 두세요\n",
    "    * factor2_vals = _두 번째 요인의 변수_\n",
    "        * 2by2 실험의 경우 비워 두세요\n",
    "    * variables_value = _변수 이름_\n",
    "    * mask_vals = _마스크에 들어갈 키워드_\n",
    "    * notch = _노치를 추가하기 위해서는 True로 설정_\n",
    "    * title = _플롯 타이틀_\n",
    "    * size = _2by2 실험은 22; 2by2by2 실험은 222_\n",
    "* 결과 플롯은 같은 디렉토리에 저장됩니다.\n",
    "* 기본적으로, 같이 제공된 부정극어 사례의 결과를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_box_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 바플롯\n",
    "\n",
    "* barplot_sample.xlsx과 같이 데이터를 정리하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_bar_plot(\"barplot_sample.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고문헌\n",
    "\n",
    "- Lin, Y., Tan, Y. C., & Frank, R. (2019). Open Sesame: Getting Inside BERT's Linguistic Knowledge. arXiv preprint arXiv:1906.01698."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torchenv)",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}